{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4d03cd5",
      "metadata": {
        "id": "f4d03cd5"
      },
      "source": [
        "# 7/13"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e065e4fc",
      "metadata": {
        "id": "e065e4fc"
      },
      "source": [
        "###DOM(Document Object Model) : 문서객체모델. XML이나 HTML문저에 접근하기 위한 일종의 인터페이스.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02767816",
      "metadata": {
        "id": "02767816"
      },
      "source": [
        "DOM(Document Object Mode)의 정의\n",
        "- HTML, XML 문서의 프로그래밍 인터페이스 : 구조화된 표현 및 프로그래밍 언어가 DOM구조에 접근할 수 있는 방법을 제공\n",
        "- 트리 구조로 형성되어 있음 : 부모 노드(위쪽), 자식 노드(아래쪽)\n",
        "- HTML에서 노드는 \\<Head>, \\<body>, \\<h1>, \\<script> 등의 태그뿐만 아니라 태그 내 텍스트나 속성 모두 노드에 속함\n",
        "- BeautifulSoup 모듈의 함수를 활용하여 노드를 기준으로 원하는 데이터 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3b70a3",
      "metadata": {
        "id": "2a3b70a3",
        "outputId": "bd0c6c16-b652-4a4b-8209-30834bef214d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "<p align=\"center\" class=\"a\"> text1</p>\n",
            "\n",
            "\n",
            "<p align=\"center\" class=\"b\"> text2</p>\n",
            "\n",
            "\n",
            "<p align=\"center\" class=\"c\"> text3</p>\n",
            "\n",
            "\n",
            "<div>\n",
            "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
            "</div>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "html=\"\"\"\n",
        "<html>\n",
        "<head>\n",
        "    <title>crawler</title>\n",
        "</head>\n",
        "<body>\n",
        "    <p class=\"a\" align=\"center\"> text1</p>\n",
        "    <p class=\"b\" align=\"center\"> text2</p>\n",
        "    <p class=\"c\" align=\"center\"> text3</p>\n",
        "    <div>\n",
        "        <img src=\"/source\" width=\"300\" height=\"200\">\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "bs = BeautifulSoup(html,\"html.parser\")\n",
        "contents = bs.find('body')\n",
        "\n",
        "### body의 children 뽑아보기\n",
        "\n",
        "for child in contents.children:\n",
        "    print(child)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269f484d",
      "metadata": {
        "id": "269f484d",
        "outputId": "da53ca3c-e082-44b2-830f-e5a41dbcac6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "<p align=\"center\" class=\"a\"> text1</p>\n",
            " text1\n",
            "\n",
            "\n",
            "<p align=\"center\" class=\"b\"> text2</p>\n",
            " text2\n",
            "\n",
            "\n",
            "<p align=\"center\" class=\"c\"> text3</p>\n",
            " text3\n",
            "\n",
            "\n",
            "<div>\n",
            "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
            "</div>\n",
            "\n",
            "\n",
            "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# body의 자손은 p, div, img\n",
        "for d in contents.descendants:\n",
        "    print(d)\n",
        "    \n",
        "### 자식들과 손자까지 나옴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef5fd06",
      "metadata": {
        "id": "3ef5fd06",
        "outputId": "f4abbb28-c374-4e78-bd54-20df2364202e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
            "--------------------------------------------------------------------------------\n",
            "<div>\n",
            "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
            "</div>\n"
          ]
        }
      ],
      "source": [
        "img_tag = contents.find('img')\n",
        "print(img_tag)\n",
        "print('-'*80)\n",
        "### 부모 찾기\n",
        "print(img_tag.parent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c81e0a",
      "metadata": {
        "id": "c0c81e0a",
        "outputId": "f2f3956a-4664-4dcd-b56b-af3e307e9cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<body>\n",
            "<p align=\"center\" class=\"a\"> text1</p>\n",
            "<p align=\"center\" class=\"b\"> text2</p>\n",
            "<p align=\"center\" class=\"c\"> text3</p>\n",
            "<div>\n",
            "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
            "</div>\n",
            "</body> \n",
            "\n",
            "<div>\n",
            "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
            "</div>\n"
          ]
        }
      ],
      "source": [
        "contents = bs.find('body')\n",
        "print(img_tag.find_parent('body'),'\\n') ### parent 중 지정해 준 body 나옴\n",
        "print(img_tag.find_parent('div')) ### parent 중 지정해 준 div만 나옴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc94891",
      "metadata": {
        "id": "ccc94891",
        "outputId": "86526fe8-06dd-447f-d55a-5d6560c6a724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<p align=\"center\" class=\"b\"> text2</p>\n"
          ]
        }
      ],
      "source": [
        "p_tag = bs.find('p',class_='b') ### 예약어와 충돌되므로 class_로 사용\n",
        "print(p_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3e889fe",
      "metadata": {
        "id": "d3e889fe",
        "outputId": "3f182bd8-ed5f-43ca-cd41-a9a9f6c81124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a> \n",
            "\n",
            "<a class=\"link_newsstand\" data-clk=\"title\" href=\"http://newsstand.naver.com/\" target=\"_blank\">뉴스스탠드</a> \n",
            "\n",
            "<a class=\"link_newsstand\" data-clk=\"title\" href=\"http://newsstand.naver.com/\" target=\"_blank\">뉴스스탠드</a> \n",
            "\n",
            "뉴스스탠드\n",
            "구독한 언론사\n",
            "전체언론사\n"
          ]
        }
      ],
      "source": [
        "from urllib import request as req\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "res = req.urlopen('https://naver.com')\n",
        "bs = BeautifulSoup(res,'html.parser')\n",
        "print(bs.find('a'),'\\n')\n",
        "print(bs.find(class_='link_newsstand'),'\\n') ### 클래스 이용해서 찾기\n",
        "print(bs.find('a',{'class':'link_newsstand'}),'\\n') ### a태그에서 딕셔너리 형태로 클래서 지정해서 찾기\n",
        "\n",
        "# 클래스가 여러개인 경우 \n",
        "# print(bs.find('a',{'class':['link_newsstand','']})) ### value값에 리스트로 넣음\n",
        "eles = bs.find_all('a',{'class':['link_newsstand','btn_sort','btn_sort.sort_on']})\n",
        "for e in eles:\n",
        "    print(e.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fc04076",
      "metadata": {
        "id": "8fc04076"
      },
      "source": [
        "###h1 글씨 제일 큼. h2, h3,... 갈수록 글씨 작아짐 h6까지 있음!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28febdf2",
      "metadata": {
        "id": "28febdf2",
        "outputId": "10ecd565-36c0-4f7a-d2b9-f186ea106dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<h1 class=\"logo_default\">\n",
            "<a class=\"logo_naver\" data-clk=\"top.logo\" href=\"/\"><span class=\"blind\">네이버</span></a>\n",
            "</h1> \n",
            "\n",
            "<h2 class=\"blind\">뉴스스탠드</h2> \n",
            "\n",
            "<h2 class=\"blind\">주제별 캐스트</h2> \n",
            "\n",
            "<h2 class=\"blind\">Sign in</h2> \n",
            "\n",
            "<h2 class=\"blind\">타임스퀘어</h2> \n",
            "\n",
            "<h3 class=\"title\"><a href=\"https://www.naver.com/NOTICE\">공지사항</a> </h3> \n",
            "\n",
            "<h3 class=\"title\">Creators</h3> \n",
            "\n",
            "<h3 class=\"title\">Partners</h3> \n",
            "\n",
            "<h3 class=\"title\">Developers</h3> \n",
            "\n",
            "<h3 class=\"blind\">네이버 정책 및 약관</h3> \n",
            "\n"
          ]
        }
      ],
      "source": [
        "hlists = bs.findAll({'h1','h2','h3','h4','h5','h6'}) ### find_all 과 findAll 과 같음!\n",
        "for h in hlists:\n",
        "    print(h, '\\n')\n",
        "### 여기엔 h1 ~ h3 까지 있었음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe1d3d0",
      "metadata": {
        "id": "dbe1d3d0",
        "outputId": "ffbf9f16-2955-46a7-a651-0c4cebbf7020",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<h1 class=\"logo_default\">\n",
            "<a class=\"logo_naver\" data-clk=\"top.logo\" href=\"/\"><span class=\"blind\">네이버</span></a>\n",
            "</h1> \n",
            "\n",
            "<h2 class=\"blind\">뉴스스탠드</h2> \n",
            "\n",
            "<h2 class=\"blind\">주제별 캐스트</h2> \n",
            "\n"
          ]
        }
      ],
      "source": [
        "hlists = bs.findAll({'h1','h2','h3','h4','h5','h6'},limit=3) ### 많이 나올 경우 개수 제한하기\n",
        "for h in hlists:\n",
        "    print(h, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85fdf8b",
      "metadata": {
        "id": "f85fdf8b",
        "outputId": "5b170445-d791-425f-c387-87eb7204cc16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "../img/gifts/img1.jpg\n",
            "../img/gifts/img2.jpg\n",
            "../img/gifts/img3.jpg\n",
            "../img/gifts/img4.jpg\n",
            "../img/gifts/img6.jpg\n"
          ]
        }
      ],
      "source": [
        "# 정규표현식과 bs4\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "html = urlopen('http://www.pythonscraping.com/pages/page3.html')\n",
        "bs = BeautifulSoup(html,'html.parser')\n",
        "images = bs.find_all('img',{'src':re.compile('\\.\\.\\/img\\/gifts\\/img.*\\.jpg')})\n",
        "# img태그 -> src = ../img/gifts/img1.jpg 로 되어있음\n",
        "for image in images:\n",
        "    print(image['src']) # 속성 뽑을 때는 대괄호"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7081e89a",
      "metadata": {
        "id": "7081e89a",
        "outputId": "78a70237-7e0f-4b51-9c43-677859088b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2,000 점\n"
          ]
        }
      ],
      "source": [
        "# 한빛 네트워크 사이트 로그인 후 점수 가져오기\n",
        "import time\n",
        "import selenium\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "driver = webdriver.Chrome('C:/tool/chromedriver.exe')\n",
        "driver.get('https://www.hanbit.co.kr/')\n",
        "element = driver.find_element_by_class_name('login')\n",
        "element.click()\n",
        "m_id = *******\n",
        "m_passwd = *******\n",
        "\n",
        "element = driver.find_element_by_id('m_id')\n",
        "element.send_keys(m_id)\n",
        "time.sleep(1)\n",
        "element = driver.find_element_by_id('m_passwd')\n",
        "element.send_keys(m_passwd)\n",
        "time.sleep(1)\n",
        "\n",
        "element = driver.find_element_by_class_name('btn_login')\n",
        "element.click()\n",
        "\n",
        "### 여기부터 BeautifulSoup 이용해보기\n",
        "driver.get('https://www.hanbit.co.kr/myhanbit/myhanbit.html')\n",
        "source = driver.page_source\n",
        "bs = BeautifulSoup(source,'html.parser')\n",
        "a = bs.select_one('#container > div > div.sm_mymileage > dl.mileage_section1 > dd > span')\n",
        "print(a.text,'점')\n",
        "time.sleep(3)\n",
        "driver.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67d3345",
      "metadata": {
        "id": "a67d3345",
        "outputId": "0d2bf969-f962-4b62-a62a-b6127b175194",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 . Nobody\n",
            "2 . Werewolves Within\n",
            "3 . Wrath Of Man\n",
            "4 . Demon Slayer - Kimetsu no Yaiba The Movie: Mugen Train (English Dubbed Version)\n",
            "5 . Till Death\n",
            "6 . Closed for Storm\n",
            "7 . Demon Slayer - Kimetsu no Yaiba The Movie: Mugen Train (Original Japanese Version)\n",
            "8 . A Quiet Place\n",
            "9 . Mortal Kombat (2021)\n",
            "10 . Cruella\n",
            "11 . Rick and Morty\n",
            "12 . Dragon Ball Super\n",
            "13 . Queen of the South\n",
            "14 . Yellowstone\n",
            "15 . The Office\n",
            "16 . The Owl House\n",
            "17 . Cowboy Bebop\n",
            "18 . Manifest\n",
            "19 . Naruto Shippuden Uncut\n",
            "20 . NCIS: Los Angeles\n",
            "21 . Mortyplicity\n",
            "22 . Mort Dinner Rick Andre\n",
            "23 . A Rickconvenient Mort\n",
            "24 . El Final\n",
            "25 . A Prueba de Balas\n",
            "26 . Plata o Plomo\n",
            "27 . El Zorro en la Gallinera\n",
            "28 . Echoes Of The Past\n",
            "29 . Separate Tides\n",
            "30 . Session #3 Honky Tonk Women\n"
          ]
        }
      ],
      "source": [
        "# Q. 구글 플레이에서 인기 영화 제목 30개 출력(requests + bs)\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://play.google.com/store/movies/top'\n",
        "res = requests.get(url)\n",
        "res.raise_for_status()\n",
        "bs = BeautifulSoup(res.text,'html.parser')\n",
        "movies = bs.find_all('div',attrs = {'class':'WsMG1c nnK0zc'})\n",
        "for i,movie in enumerate(movies):\n",
        "    print(i+1,\".\",movie.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ec0183",
      "metadata": {
        "id": "89ec0183",
        "outputId": "a46cbbf9-9e8f-4ec4-e1f3-b94d1fabb895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "스크롤 완료\n",
            "\n",
            "200 \n",
            "\n",
            "1 . 노바디\n",
            "2 . 콰이어트 플레이스 (자막판)\n",
            "3 . Cruella\n",
            "4 . 캐시트럭\n",
            "5 . 어벤져스 : 엔드게임 (자막판)\n",
            "6 . 고질라 VS. 콩\n",
            "7 . 크루즈 패밀리: 뉴 에이지\n",
            "8 . 너의 이름은. (자막판)\n",
            "9 . 테넷\n",
            "10 . 어벤져스 : 인피니티 워 (자막판)\n",
            "11 . 라야와 마지막 드래곤\n",
            "12 . 날씨의 아이 (자막)\n",
            "13 . 킬러의 보디가드\n",
            "14 . 스파이더맨: 파 프롬 홈 (자막판)\n",
            "15 . 소울\n",
            "16 . 해리포터와 마법사의 돌\n",
            "17 . 목소리의 형태 (자막판)\n",
            "18 . 베놈   Venom\n",
            "19 . 킬러의 보디가드 무삭제 특별판 (자막판)\n",
            "20 . 캡틴 아메리카 : 시빌 워 (자막판)\n",
            "21 . 형님 아내2 (무삭제)\n",
            "22 . 조커\n",
            "23 . 잭 스나이더의 저스티스 리그\n",
            "24 . 겨울왕국 2 (더빙판)\n",
            "25 . 건마의 신:어린 아내의 알바\n",
            "26 . 스파이더맨 : 뉴 유니버스\n",
            "27 . 어벤져스 (자막판)\n",
            "28 . 위대한 쇼맨 (자막판)\n",
            "29 . 몬스터 헌터 Monster Hunter\n",
            "30 . 원더우먼 1984\n",
            "31 . 기생충\n",
            "32 . 레디 플레이어 원\n",
            "33 . 겨울왕국 2 (자막판)\n",
            "34 . 어벤져스 : 에이지 오브 울트론 (자막판)\n",
            "35 . 분노의 질주: 홉스 & 쇼\n",
            "36 . 라라랜드 (자막판)\n",
            "37 . 50가지 그림자:해방 (자막판)\n",
            "38 . 존 윅-리로드\n",
            "39 . 어벤져스 : 엔드게임 (더빙판)\n",
            "40 . 씽 (더빙판)\n",
            "41 . 미나리\n",
            "42 . 캡틴 아메리카: 윈터 솔져 (자막판)\n",
            "43 . 일탈여행: 프라이빗 아일랜드\n",
            "44 . 미스트\n",
            "45 . 모아나 (자막판)\n",
            "46 . 캡틴 마블 (자막판)\n",
            "47 . 어벤져스 : 인피니티 워 (더빙판)\n",
            "48 . 해리포터와 비밀의방\n",
            "49 . 스파이더맨: 홈커밍  (자막판)\n",
            "50 . 주토피아 (더빙판)\n",
            "51 . 아이언맨 2\n",
            "52 . 마크맨\n",
            "53 . 일본 막장 불륜 호텔\n",
            "54 . 너의 이름은. (더빙판)\n",
            "55 . 분노의 질주 7\n",
            "56 . 모탈 컴뱃\n",
            "57 . 아바타\n",
            "58 . 닥터 스트레인지 (자막판)\n",
            "59 . 해리포터와 아즈카반의 죄수\n",
            "60 . 50가지 그림자: 심연\n",
            "61 . 가디언즈 오브 갤럭시\n",
            "62 . 토르 : 라그나로크 (자막판)\n",
            "63 . 아이언맨\n",
            "64 . 엄마의 남자\n",
            "65 . 모아나 (더빙판)\n",
            "66 . 스캔들\n",
            "67 . 쥬라기 월드 : 폴른 킹덤\n",
            "68 . 헝거게임: 더 파이널\n",
            "69 . 알라딘 (2019) (자막판)\n",
            "70 . 몬스터 호텔 3 (더빙판)\n",
            "71 . 분노의 질주: 더 익스트림\n",
            "72 . 코코 (자막판)\n",
            "73 . 존윅 3: 파라벨룸\n",
            "74 . 내가 죽기를 바라는 자들\n",
            "75 . 나쁜 녀석들 : 포에버 Bad Boys for Life\n",
            "76 . 메이즈 러너: 데스 큐어 (자막판)\n",
            "77 . 노매드랜드\n",
            "78 . 인터스텔라\n",
            "79 . 주토피아 (자막판)\n",
            "80 . 해리포터와 불의잔\n",
            "81 . 포드 V 페라리 (자막판)\n",
            "82 . 더 스파이\n",
            "83 . 성판17: 남자들의 17가지 성적 판타지\n",
            "84 . 컨저링\n",
            "85 . 그린랜드\n",
            "86 . 가디언즈 오브 갤럭시 VOL. 2 (자막판)\n",
            "87 . 더 울프 오브 월스트리트\n",
            "88 . 삼국지: 무신 조자룡\n",
            "89 . 마이펫의 이중생활 2\n",
            "90 . 내부자들: 디 오리지널\n",
            "91 . 드래곤 길들이기 3 (더빙판)\n",
            "92 . 워 위드 그랜파\n",
            "93 . 라이더스 오브 저스티스\n",
            "94 . 톰과 제리\n",
            "95 . 고질라: 킹 오브 몬스터 (자막판)\n",
            "96 . 헝거게임: 모킹제이\n",
            "97 . 해리포터와 불사조 기사단\n",
            "98 . 시간을 달리는 소녀_자막 (자막판)\n",
            "99 . 날씨의 아이 (더빙)\n",
            "100 . 해리포터와 혼혈왕자\n",
            "101 . 코코 (더빙판)\n",
            "102 . 이 멋진 세계에 축복을! 붉은 전설\n",
            "103 . 아이언맨 3\n",
            "104 . 캐리비언의 해적: 블랙펄의 저주\n",
            "105 . 해리포터 시리즈 완결 패키지\n",
            "106 . 명탐정 피카츄 (더빙판)\n",
            "107 . 헝거게임 : 판엠의 불꽃\n",
            "108 . 해리포터와 죽음의 성물 파트1 (자막판)\n",
            "109 . 핵소고지 (자막판)\n",
            "110 . 보헤미안 랩소디 (자막판)\n",
            "111 . 겨울왕국 (자막판)\n",
            "112 . 그것: 두 번째 이야기\n",
            "113 . 언터처블: 1%의 우정\n",
            "114 . 리스타트\n",
            "115 . 퍼스트 어벤져 (자막판)\n",
            "116 . 크루즈패밀리 (더빙판)\n",
            "117 . 조제\n",
            "118 . 다크 나이트\n",
            "119 . 비긴 어게인 (자막판)\n",
            "120 . 겨울왕국 (더빙판)\n",
            "121 . 부산행\n",
            "122 . 해리포터와 죽음의 성물 파트 2 (자막판)\n",
            "123 . 매트릭스\n",
            "124 . 쥬라기 월드\n",
            "125 . 어니스트 씨프\n",
            "126 . 애나벨 집으로 (자막판)\n",
            "127 . 매너선생님\n",
            "128 . 스캔들3\n",
            "129 . 노트북\n",
            "130 . 바람에 젖은 여자\n",
            "131 . 슈퍼 소닉\n",
            "132 . 아쿠아맨\n",
            "133 . 알리타: 배틀 엔젤 (자막판)\n",
            "134 . 자산어보\n",
            "135 . 페이트 스테이 헤븐즈필 제3장 스프링 송\n",
            "136 . 여고괴담 여섯번째 이야기 : 모교\n",
            "137 . 컨저링 2 (자막판)\n",
            "138 . 캐리비안의 해적: 망자의 함\n",
            "139 . 분노의 질주: 더 맥시멈\n",
            "140 . 쿵푸팬더 3 (더빙판)\n",
            "141 . 미드소마\n",
            "142 . 더 언홀리 Unholy, The\n",
            "143 . 컨저링 (자막판)\n",
            "144 . 괴물의 아이 (자막판)\n",
            "145 . 캡틴 아메리카 : 시빌 워 (더빙판)\n",
            "146 . 패스트 & 퓨리어스 - 도쿄 드리프트\n",
            "147 . 미드웨이\n",
            "148 . 분노의 질주: 더 오리지널\n",
            "149 . 라푼젤 (자막판)\n",
            "150 . 명탐정 피카츄 (자막판)\n",
            "151 . 엔조이닷컴\n",
            "152 . 버즈 오브 프레이(할리 퀸의 황홀한 해방)\n",
            "153 . 슈퍼배드 3\n",
            "154 . 덫: 치명적인 유혹\n",
            "155 . 1917\n",
            "156 . 토르 : 천둥의 신 (자막판)\n",
            "157 . 언니들의 속사정: 탐욕의 길\n",
            "158 . 스타 이즈 본\n",
            "159 . 늑대아이_자막\n",
            "160 . 백두산\n",
            "161 . 미션 임파서블: 폴아웃 (자막판)\n",
            "162 . 마녀를 잡아라\n",
            "163 . 주먹왕 랄프 2 : 인터넷 속으로 (더빙판)\n",
            "164 . 더 넌 (자막판)\n",
            "165 . 데드풀2 (자막판)\n",
            "166 . 스폰지밥 (더빙판)\n",
            "167 . 인셉션\n",
            "168 . 바리새인\n",
            "169 . 마다가스카의 펭귄들\n",
            "170 . 라푼젤 (더빙판)\n",
            "171 . 분노의 질주 2\n",
            "172 . 전망 좋은 집\n",
            "173 . 쌍화점\n",
            "174 . 캐리비안의 해적: 세상의 끝에서\n",
            "175 . 닥터 스트레인지 (더빙판)\n",
            "176 . 빅쇼트\n",
            "177 . 트랜스포머: 최후의 기사 (자막판)\n",
            "178 . 인사이드 아웃 (더빙판)\n",
            "179 . 형님 아내2\n",
            "180 . 비밀애\n",
            "181 . 어스 (자막판)\n",
            "182 . 토이 스토리 4 (더빙판)\n",
            "183 . The Meg\n",
            "184 . 엣지 오브 투모로우\n",
            "185 . 그레이의 50가지 그림자\n",
            "186 . 분노의 질주\n",
            "187 . 딸의 친구2\n",
            "188 . 겟아웃 (자막판)\n",
            "189 . 마이펫의 이중생활 (더빙판)\n",
            "190 . 2067\n",
            "191 . 아웃포스트\n",
            "192 . 인간중독\n",
            "193 . 반도\n",
            "194 . 라따뚜이 (자막판)\n",
            "195 . 파이프라인\n",
            "196 . 퍼시픽 림: 업라이징 (자막판)\n",
            "197 . 다만악에서구하소서\n",
            "198 . 괴물의 아이 (더빙판)\n",
            "199 . 새엄마들 2019\n",
            "200 . 분노의 질주: 언리미티드\n"
          ]
        }
      ],
      "source": [
        "# headless chrome ### 화면에 안 띄우고 처리\n",
        "from selenium import webdriver\n",
        "import time\n",
        "\n",
        "# headless 옵션 넣기\n",
        "options = webdriver.ChromeOptions()\n",
        "options.headless = True\n",
        "options.add_argument('widndow-size = 1920x1080') ### 안띄워서 보이진 않지만 뒤에서 이 사이즈의 창으로 작업함\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome('C:/tool/chromedriver.exe', options = options)\n",
        "driver.maximize_window()\n",
        "\n",
        "url = 'https://play.google.com/store/movies/top'\n",
        "driver.get(url)\n",
        "\n",
        "# 1080 위치로 스크롤 내리기\n",
        "driver.execute_script('window.scrollTo(0,1080)') \n",
        "# 화면 가장 아래로 스크롤 내리기\n",
        "driver.execute_script('window.scrollTo(0,document.body.scrollHeight)') ### 스크롤을 끝까지 내림\n",
        "\n",
        "interval = 2 # 2초에 한번씩 스크롤 내리기\n",
        "\n",
        "# 현재 문서 높이를 가져와서 저장\n",
        "prev_height = driver.execute_script('return document.body.scrollHeight') # return은 실행하는거\n",
        "\n",
        "# 반복 수행\n",
        "while True:\n",
        "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
        "    # 페이지 로딩대기\n",
        "    time.sleep(interval)\n",
        "    curr_height = driver.execute_script('return document.body.scrollHeight')\n",
        "    if curr_height == prev_height:\n",
        "        break\n",
        "    prev_height = curr_height\n",
        "print('스크롤 완료\\n')\n",
        "\n",
        "bs = BeautifulSoup(driver.page_source,'html.parser')\n",
        "movies = bs.find_all('div',attrs = {'class':'WsMG1c nnK0zc'})\n",
        "\n",
        "print(len(movies),\"\\n\")\n",
        "for i,movie in enumerate(movies):\n",
        "    print(i+1,\".\",movie.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b51b82",
      "metadata": {
        "id": "62b51b82",
        "outputId": "014f7b65-1399-4441-e944-fa4f11155857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/91.0.4472.124 Safari/537.36\n"
          ]
        }
      ],
      "source": [
        "# headless chrome \n",
        "from selenium import webdriver\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.headless = True\n",
        "options.add_argument('widndow-size = 1920x1080')\n",
        "options.add_argument('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome('C:/tool/chromedriver.exe', options = options)\n",
        "driver.maximize_window()\n",
        "\n",
        "url = 'https://www.whatismybrowser.com/detect/what-is-my-user-agent'\n",
        "driver.get(url)\n",
        "\n",
        "detected_value = driver.find_element_by_id('detected_value')\n",
        "print(detected_value.text)\n",
        "driver.quit()\n",
        "\n",
        "### 결과에 HeadlessChrome 이라고 나옴."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "9_web_crawling_응용_guide.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}